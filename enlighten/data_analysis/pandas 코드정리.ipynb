{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 판다스 코드정리",
   "id": "da270ead803be558"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 위도와 경도에 111을 곱해 반경에 있는 발전소를 찾는 코드",
   "id": "2575ac1f754c276f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in new_daily.plant_id[new_daily.plant_id.isin(plant_list.plant_id)].unique():\n",
    "    for t in range(1,31):\n",
    "        target_lat = new_daily.latitude[new_daily.plant_id==i].values[0]\n",
    "        target_long = new_daily.longitude[new_daily.plant_id==i].values[0]\n",
    "        target_pv = new_daily.avg_pv_time[new_daily.plant_id==i].values[0]\n",
    "        df_pm2 = new_daily[new_daily.plant_id!=i]\n",
    "        df_pm2['target_plant_id'] = i\n",
    "        df_pm2['distance']=np.sqrt((df_pm2.latitude-target_lat)**2+(df_pm2.longitude-target_long)**2)*111\n",
    "        df_pm3 = df_pm2[df_pm2.distance<=t].sort_values(['distance'])\n",
    "        legion_avg = np.nanmean(df_pm3.avg_pv_time[(df_pm3.avg_pv_time>0)&(df_pm3.avg_pv_time<10)])\n",
    "        if len(df_pm3)>30:\n",
    "            print(i,\"  :   \", np.round(target_pv/legion_avg,2),\"발전소 수: \",len(df_pm3), \"반경:  \" ,t)\n",
    "            plant_id +=[i]\n",
    "            pvtime_percent +=[np.round(target_pv/legion_avg,2)]\n",
    "            plant_count +=[len(df_pm3)]\n",
    "            plant_range +=[t]\n",
    "            break\n",
    "        if t==30 and len(df_pm3)<30:\n",
    "            no+=[i]\n",
    "            plant_id +=[i]\n",
    "            pvtime_percent +=[np.round(target_pv/legion_avg,2)]\n",
    "            plant_count +=[len(df_pm3)]\n",
    "            plant_range +=[t]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 지역별 통계를 위해 통계값 기반 전처리 코드",
   "id": "80960e3647d07521"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "gld_threshold_2020_low= gld_2020[['base_date','location_group_code','avg_pv_time']].groupby(['base_date','location_group_code']).apply(lambda x: x.median()-3*1.4826*median_absolute_deviation(x)).reset_index()\n",
    "\n",
    "gld_threshold_2020_up= gld_2020[['base_date','location_group_code','avg_pv_time']].groupby(['base_date','location_group_code']).apply(lambda x: x.median()+3*1.4826*median_absolute_deviation(x)).reset_index()\n",
    "\n",
    "gld_threshold_2020_up.columns =['base_date', 'location_group_code', 'threshold_upper']\n",
    "gld_threshold_2020_low.columns =['base_date', 'location_group_code', 'threshold_lower']\n",
    "\n",
    "gld_2020_2 = pd.merge(gld_2020,gld_threshold_2020_low,on=['location_group_code','base_date'])\n",
    "\n",
    "gld_2020_2 = pd.merge(gld_2020_2,gld_threshold_2020_up,on=['location_group_code','base_date'])\n",
    "\n",
    "gld_2020_3 = gld_2020_2[(gld_2020_2.avg_pv_time>=gld_2020_2.threshold_lower)&(gld_2020_2.avg_pv_time<gld_2020_2.threshold_upper)].reset_index(drop=True)\n",
    "\n",
    "day_2020= pd.DataFrame(Counter(gld_2020_3.plant_id).items(),columns=['plant_id','day_count'])\n",
    "\n",
    "final_list_2020= list(day_2020.plant_id[day_2020.day_count>=365])\n",
    "\n",
    "gld_2020_4 = pd.merge(gld_2020_3,day_2020,on='plant_id')\n",
    "\n",
    "gld_2020_5 = gld_2020_4[gld_2020_4.day_count>=365].reset_index(drop=True)\n",
    "\n",
    "gld_2020_5['month']=[x[:7] for x in gld_2020_5.base_date]\n",
    "\n",
    "gld_2020_5.location_group_code=[np.int(x) for x in gld_2020_5.location_group_code]\n",
    "\n",
    "gld_2020_6= gld_2020_5.pivot_table(index=['plant_id','month'],values=['avg_pv_time','location_group_code','pv_capacity','day_count'],aggfunc=np.mean).reset_index()\n",
    "\n",
    "gld_2020_6.location_group_code = [str(x) for x in gld_2020_6.location_group_code]\n",
    "\n",
    "\n",
    "\n",
    "gld_2020_6_pv_amount = gld_2020_5.pivot_table(index=['plant_id','month'],values='pv_amount',aggfunc=np.sum).reset_index()\n",
    "\n",
    "gld_2020_7 = pd.merge(gld_2020_6,gld_2020_6_pv_amount,on=[\"plant_id\",\"month\"])\n",
    "\n",
    "gld_2020_8 = pd.merge(gld_2020_7,sido,on='location_group_code')\n",
    "\n",
    "\n",
    "\n",
    "len(gld_2020_8.plant_id.unique())\n",
    "\n",
    "sum(gld_2020_8.drop_duplicates(['plant_id']).pv_capacity)\n",
    "\n",
    "gld_2020_9= pd.merge(gld_2020_8,pm[['plant_id','address']],on='plant_id')\n",
    "\n",
    "gld_2020_9.columns = ['발전소id','월','발전시간','발전일수','지역코드','발전용량','총발전량','지역구분','주소']"
   ],
   "id": "9b3021622c9e918b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4df99f4430c5cb91"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def getGPS(addr):\n",
    "    addr = str(addr)\n",
    "    if ((addr.split()[-1]=='.') | (addr.split()[-1]=='-')):\n",
    "        addr = ' '.join(addr.split()[:-1])\n",
    "    count =0\n",
    "    is_bad = False\n",
    "    with requests.Session() as s:\n",
    "        while count ==0:\n",
    "            params = {'X-NCP-APIGW-API-KEY-ID' : ID, 'X-NCP-APIGW-API-KEY' : KEY,\n",
    "                      'query' : addr}\n",
    "            response = s.get('https://naveropenapi.apigw.ntruss.com/map-geocode/v2/geocode', params=params)\n",
    "            result = response.json()\n",
    "            if result['status']!='OK':\n",
    "                print('have no adress')\n",
    "                return {130, 37, True}\n",
    "            count = result['meta']['totalCount']\n",
    "            if count !=0:\n",
    "                lon = result['addresses'][0]['x']\n",
    "                lat = result['addresses'][0]['y']\n",
    "                roadadrr = result['addresses'][0]['roadAddress']\n",
    "                jibunaddr = result['addresses'][0]['jibunAddress']\n",
    "                #                 print(lon)\n",
    "                ret = {'count' : count, 'lon' : lon, 'lat' : lat, 'road' : roadadrr, 'jibun' : jibunaddr, 'is_bad':is_bad}\n",
    "                #                 print(lon, lat, is_bad)\n",
    "                return [np.float32(lon), np.float32(lat), is_bad]\n",
    "            addr= ' '.join(addr.split()[:-1])"
   ],
   "id": "bc660ad8ebdc7ead"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 다양한 전처리 내용. feature를 후행, 선행으로 만드는 작업도 포함되어 있음",
   "id": "a83500f087b33dfe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df2 = df.sort_values(['analysis_time']).reset_index(drop=True)\n",
    "df2['analysis_time_kst'] = [x.astimezone(pytz.timezone('Asia/Seoul')) for x in df2.analysis_time]\n",
    "\n",
    "df2['lead_hour_timedelta'] = [timedelta(hours=x) for x in df2.lead_hour]\n",
    "df2['base_time'] = df2.analysis_time_kst + df2.lead_hour_timedelta\n",
    "df2['base_hour'] = [x.hour for x in df2.base_time]\n",
    "df2['base_date'] = [x.date().strftime('%Y-%m-%d') for x in df2.base_time]\n",
    "df2['analysis_hour'] = [x.time().hour for x in df2.analysis_time]\n",
    "df_0 = df2[(df2.analysis_hour.isin([0])) & (df2.lead_hour >= 15)].drop_duplicates(['base_date', 'base_hour'],\n",
    "                                                                                  keep='last').sort_values(\n",
    "    ['base_date', 'base_hour']).reset_index(drop=True)\n",
    "df_0_result = df_0[(df_0.base_date >= '2021-10-01') & (df_0.base_date < '2021-11-01')].reset_index(drop=True)\n",
    "df_0_result = df_0_result[\n",
    "    ['base_date', 'base_hour', 'total_shortwave', 'temperature', \"humidity_relative\", \"pressure_msl\", \"cloud_total_max\",\n",
    "     \"analysis_time_kst\", 'lead_hour']]\n",
    "df_0_result['total_shortwave_lead_1'] = df_0_result.total_shortwave.shift(\n",
    "    -1).fillna(0)\n",
    "df_0_result['sunny_radiation'] = sunny_rad.IC\n",
    "\n",
    "df_0_result.temperature -= 273.15\n",
    "df_0_result.pressure_msl /= 100\n",
    "df_0_result.cloud_total_max *= 10\n",
    "df_0_result['sunny_radiation_lead_1'] = df_0_result.sunny_radiation.shift(\n",
    "    -1).fillna(0)\n",
    "df_0_result['temperature_lead_1'] = df_0_result.temperature.shift(-1).fillna(\n",
    "    method=\"ffill\")\n",
    "df_0_result['humidity_relative_lead_1'] = df_0_result.humidity_relative.shift(\n",
    "    -1).fillna(\n",
    "    method=\"ffill\")\n",
    "df_0_result['pressure_msl_lead_1'] = df_0_result.pressure_msl.shift(\n",
    "    -1).fillna(\n",
    "    method=\"ffill\")\n",
    "df_0_result['cloud_total_max_lead_1'] = df_0_result.cloud_total_max.shift(\n",
    "    -1).fillna(\n",
    "    method=\"ffill\")\n",
    "df_0_result['total_shortwave_lead_2'] = df_0_result.total_shortwave.shift(\n",
    "    -2).fillna(0)"
   ],
   "id": "5b7d9d2e9a75ccf2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## seq 데이터셋 만드는 것",
   "id": "5b7f7882b3692be4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "base_date = []\n",
    "base_hour = []\n",
    "for i in range(160,len(train)-160):\n",
    "    train_x+=[np.array(np.array(train[feature][i:i+160]).transpose())]\n",
    "    train_y+=[train.pptot.values[i:i+160]]\n",
    "    base_date +=[train.base_date.values[i:i+160]]\n",
    "    base_hour+=[train.base_time.values[i:i+160]]"
   ],
   "id": "b0e70f013a2df57b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## lag 변수 만들기",
   "id": "76bc51a2253ced25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "new_df = pd.DataFrame()\n",
    "for i in df.category.unique():\n",
    "    df_ = df[df.category==i]\n",
    "    df_['pptot_lag_160'] = df_.pptot.shift(160)\n",
    "    df_['pptot_lag_96'] = df_.pptot.shift(96)\n",
    "    df_['pptot_lag_48'] = df_.pptot.shift(48)\n",
    "    df_['pptot_lag_24'] = df_.pptot.shift(24)\n",
    "    df_['pptot_lag_12'] = df_.pptot.shift(12)\n",
    "    df_['pptot_lag_6'] = df_.pptot.shift(6)\n",
    "    df_ = df_[160:]\n",
    "    new_df = new_df.append(df_)"
   ],
   "id": "2fe7b13a565a5aff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
